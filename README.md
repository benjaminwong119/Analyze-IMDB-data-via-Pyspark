# Analyze-IMDB-data-via-Pyspark

## Introduction
The purpose of this project is to learn more about Apache Spark, a data processing framework that can quickly perform large-scale data processing by using clusters. A Spark cluster is provisioned on Amazon EMR and is connected to Jupyter Notebook to run queries using PySpark, the Python API for Apache Spark. 

## Dataset

The dataset being used for data analysis is a IMDB dataset found on Kaggle: https://www.kaggle.com/datasets/ashirwadsangwan/imdb-dataset. This dataset is used to emulate data that is too large to run by memory which requires the use of provisioning infrastructure using the Amazon EMR Ecosystem. 
